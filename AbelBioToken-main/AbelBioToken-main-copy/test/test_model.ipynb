{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d54c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from google.colab import drive\n",
    "import sys\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Add necessary directories to sys.path\n",
    "sys.path.append('/content/drive/My Drive/AbelBioToken-main/AbelBioToken-main/data')\n",
    "sys.path.append('/content/drive/My Drive/AbelBioToken-main/AbelBioToken-main/model')\n",
    "sys.path.append('/content/drive/My Drive/AbelBioToken-main/AbelBioToken-main/train')\n",
    "sys.path.append('/content/drive/My Drive/AbelBioToken-main/AbelBioToken-main/test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d174af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import context\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import csv\n",
    "import random\n",
    "\n",
    "from model.transformer import Transformer\n",
    "from train.dataset import get_dataloader, DataCtg\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model_path = os.path.join(context.current_dir, \"transformer_model.pth\")\n",
    "\n",
    "model = torch.load(model_path)\n",
    "model = model.to(device)\n",
    "\n",
    "test_dataloader, _, _ = get_dataloader(DataCtg.TEST, 16)\n",
    "test_data = list(test_dataloader)\n",
    "\n",
    "flattened_test_data = []\n",
    "for batch in test_data:\n",
    "    labels, tokens = batch\n",
    "    for i in range(labels.size(0)):\n",
    "        flattened_test_data.append((labels[i], tokens[i]))\n",
    "\n",
    "random.shuffle(flattened_test_data)\n",
    "\n",
    "# Select the first 30 sequences\n",
    "# selected_data = flattened_test_data[:30]\n",
    "selected_data = flattened_test_data[:-1]\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=24)\n",
    "\n",
    "\n",
    "def calculate_accuracy(predictions, targets):\n",
    "    first_one_index = (targets == 1).nonzero(as_tuple=True)[1]\n",
    "    mask = torch.arange(targets.size(1)).expand_as(\n",
    "        targets\n",
    "    ) <= first_one_index.unsqueeze(1)\n",
    "    _, preds = torch.max(predictions, dim=-1)\n",
    "    correct = (preds == targets).float()\n",
    "    correct = correct * mask.float()\n",
    "    accuracy = correct.sum() / mask.sum()\n",
    "    return accuracy.item()\n",
    "\n",
    "\n",
    "# Open a CSV file to write the results\n",
    "with open(\"random_test_results.csv\", mode=\"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Input Tokens\", \"True Labels\", \"Predictions\"])\n",
    "\n",
    "    # Evaluate the model on the selected data and write predictions to CSV\n",
    "    model.eval()\n",
    "    test_running_loss, test_running_corrects, test_total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for label, token in selected_data:\n",
    "            token, label = token.unsqueeze(0).to(device), label.unsqueeze(0).to(\n",
    "                device, dtype=torch.long\n",
    "            )\n",
    "            out = model(token, label)\n",
    "            loss = criterion(out.view(-1, out.size(-1)), label.view(-1))\n",
    "            test_running_loss += loss.item() * token.size(0)\n",
    "            test_running_corrects += calculate_accuracy(out, label) * token.size(0)\n",
    "            test_total += token.size(0)\n",
    "            print(\n",
    "                f\"Cumulative Accuracy :{test_running_corrects/test_total} in {test_total} data.\"\n",
    "            )\n",
    "\n",
    "            # Get the predictions\n",
    "            _, preds = torch.max(out, dim=-1)\n",
    "\n",
    "            # Write the data and predictions to the CSV file\n",
    "            writer.writerow(\n",
    "                [\n",
    "                    token.cpu().numpy().tolist(),\n",
    "                    label.cpu().numpy().tolist(),\n",
    "                    preds.cpu().numpy().tolist(),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "test_loss = test_running_loss / test_total\n",
    "test_acc = test_running_corrects / test_total\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
