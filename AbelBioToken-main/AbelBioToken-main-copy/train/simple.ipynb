{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3900c60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from google.colab import drive\n",
    "import sys\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Add necessary directories to sys.path\n",
    "sys.path.append('/content/drive/My Drive/AbelBioToken-main/AbelBioToken-main/data')\n",
    "sys.path.append('/content/drive/My Drive/AbelBioToken-main/AbelBioToken-main/model')\n",
    "sys.path.append('/content/drive/My Drive/AbelBioToken-main/AbelBioToken-main/train')\n",
    "sys.path.append('/content/drive/My Drive/AbelBioToken-main/AbelBioToken-main/test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffab195b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import context\n",
    "\n",
    "from model.transformer import Transformer\n",
    "\n",
    "src_vocab_size = 11\n",
    "target_vocab_size = 11\n",
    "num_layers = 6\n",
    "seq_length = 12\n",
    "\n",
    "source = torch.tensor(\n",
    "    [[0, 2, 5, 6, 4, 3, 9, 5, 2, 9, 10, 1], [0, 2, 8, 7, 3, 4, 5, 6, 7, 2, 10, 1]]\n",
    ")\n",
    "\n",
    "target = torch.tensor(\n",
    "    [[0, 1, 7, 4, 3, 5, 9, 2, 8, 10, 9, 1], [0, 1, 5, 6, 2, 4, 7, 6, 2, 8, 10, 1]]\n",
    ")\n",
    "\n",
    "print(source.shape, target.shape)\n",
    "\n",
    "model = Transformer(\n",
    "    embed_dim=512,\n",
    "    src_vocab_size=src_vocab_size,\n",
    "    target_vocab_size=target_vocab_size,\n",
    "    src_seq_length=seq_length,\n",
    "    trg_seq_length=seq_length,\n",
    "    num_layers=num_layers,\n",
    "    expansion_factor=4,\n",
    "    n_heads=8,\n",
    ")\n",
    "# print(model)\n",
    "\n",
    "out = model(source, target)\n",
    "print(out.shape)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
